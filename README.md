<h1>Cognisense: A Multi-Modal Sentiment Analyzer</h1>

Cognisense is an AI-powered Multi-Modal Sentiment Analysis system that detects and analyzes human emotions using multiple input modalities including text, audio, image, and video. The system combines Natural Language Processing (NLP), Computer Vision, and Audio Signal Processing techniques to generate comprehensive sentiment insights.

<hr>

<h2><b>Project Overview:</b></h2>

Traditional sentiment analysis focuses only on text. Cognisense goes beyond that by integrating:
<ul>
<li>Text Sentiment Analysis</li>
<li>Audio Emotion Detection</li>
<li>Image-Based Facial Emotion Recognition</li>
<li>Video Sentiment Analysis</li>
<li>Real-Time Video Emotion Analysis</li>
</ul>

By combining multiple modalities, Cognisense provides more accurate and context-aware sentiment predictions.


<hr>

<h2>Features</h2>
<ul>
<li>Multi-modal emotion prediction</li>
<li>Real-time detection using webcam</li>
<li>Interactive user interface</li>
<li>Modular analyzer architecture</li>
<li>Visualization using charts</li>
</ul>

<hr>

<h2>Project Structure</h2>

<pre>
Cognisense/
â”‚
â”œâ”€â”€ analyzers/
â”‚   â”œâ”€â”€ text_analyzer.py
â”‚   â”œâ”€â”€ audio_analyzer.py
â”‚   â”œâ”€â”€ image_analyzer.py
â”‚   â”œâ”€â”€ video_analyzer.py
â”‚   â””â”€â”€ realtime_video_analyzer.py
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/styles.css
â”‚   â””â”€â”€ js/main.js
â”‚
â”œâ”€â”€ templates/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ utils.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
</pre>

<hr>

<h2>Technologies Used</h2>
<ul>
<li>Python</li>
<li>Flask</li>
<li>TensorFlow</li>
<li>OpenCV</li>
<li>Librosa</li>
<li>Scikit-learn</li>
<li>HTML, CSS, JavaScript</li>
</ul>

<hr>

<h2>Installation</h2>

<h3>Clone Repository</h3>
<pre>git clone https://github.com/GazanfarAnsari10/Cognisense-A-Multi-Modal-Sentiment-Analyzer.git</pre>

<h3>Create Virtual Environment</h3>
<pre>python -m venv venv</pre>

<h3>Activate Environment (Windows)</h3>
<pre>venv\Scripts\activate</pre>

<h3>Install Dependencies</h3>
<pre>pip install -r requirements.txt</pre>

<h3>Run Application</h3>
<pre>python app.py</pre>

<hr>

<h2>How It Works</h2>
<ul>
<li>Text processed using NLP models</li>
<li>Audio analyzed using MFCC and spectral features</li>
<li>Images and video processed using facial emotion recognition</li>
<li>Real-time webcam emotion detection</li>
<li>Results visualized on dashboard</li>
</ul>

<hr>

<h2>Use Cases</h2>
<ul>
<li>Social media sentiment monitoring</li>
<li>Customer feedback analysis</li>
<li>Mental health analysis</li>
<li>Human-computer interaction</li>
<li>Market research</li>
</ul>

<hr>

<h2>Future Enhancements</h2>
<ul>
<li>Multimodal deep learning fusion model</li>
<li>Cloud deployment</li>
<li>API integration</li>
<li>Faster inference optimization</li>
</ul>

<hr>

<h2>Author</h2>
<p>
<b>Mohammad Gazanfar Ansari</b><br>
B.Tech â€“ Artificial Intelligence & Machine Learning
</p>

<hr>

<h2>Connect With Me ðŸ”—</h2>

<p>
<a href="https://www.linkedin.com/in/mohammad-gazanfar-ansari" target="_blank">
LinkedIn</a>
&nbsp; | &nbsp;
<a href="mailto:gazi.freestyle@gmail.com">
Email</a>
</p>

<hr>

<h2>License</h2>
<p>This project is for academic and research purposes.</p>
